{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ —Ç—É—Ç –µ—Å—Ç—å:  \n",
    "- —á—Ç–µ–Ω–∏–µ –∏–∑ .txt\n",
    "- —É–¥–∞–ª–µ–Ω–∏–µ emoji\n",
    "- –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤\n",
    "- —Å–∞–º—ã–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ–º—ã–µ –∏ –∏—Ö —É–¥–∞–ª–µ–Ω–∏–µ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(self, submit):\n",
    "    df = self.answers.join(submit, on='id')\n",
    "\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    for idx, row in df.iterrows():\n",
    "        answer_labels = row['labels'].split(',')\n",
    "        y_true.append([1 if label in answer_labels else 0 for label in LABELS])\n",
    "        y_scores.append([row['normal'], row['insult'], row['obscenity'], row['threat']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-87a08c16ae4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mthr\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mj\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[1;31m# maybe partial set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[0mtake_split_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[1;31m# if there is only one block/type, still have to take split path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_is_mixed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5373\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5376\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5334\u001b[0m         \"\"\"\n\u001b[0;32m   5335\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5336\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5371\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5373\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5374\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mis_mixed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_mixed_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;31m# Warning, consolidation needs to get checked upstairs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [['id', 'text', 'normal','insult','obscenity','threat']]);\n",
    "j=0;\n",
    "\n",
    "f = open(\"data/train.txt\", \"r\", encoding='utf-8')\n",
    "for line in f:\n",
    "    nor, ins, obs, thr = [0,0,0,0]\n",
    "    l = line.split('\\t')\n",
    "    em_List = (l[1:-1])\n",
    "    for i in em_List:\n",
    "        if i=='__label__NORMAL':\n",
    "            nor+=1\n",
    "        elif i=='__label__INSULT':\n",
    "            ins+=1\n",
    "        elif i=='__label__OBSCENITY':\n",
    "            obs+=1\n",
    "        else:\n",
    "            thr+=1\n",
    "    df.loc[j]=[int(l[0]),l[-1][:-1],nor,ins,obs,thr]\n",
    "    j += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lenght=148775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2000).to_csv('short_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π, –ø–æ—ç—Ç–æ–º—Ü —Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–∫–∞ –±—É–¥—É —Ç–æ–ª—å–∫–æ —Å –ø–µ—Ä–≤—ã–º–∏ 2000 —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–Ω–µ—Å–µ–Ω—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–¥ short_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>normal</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>15834</td>\n",
       "      <td>–ª—é–¥–µ–π –∏—Å–∫–∏—Å—Ç–≤–∞ —Ç—è–Ω–µ—Ç ,–æ–Ω –Ω–µ —Å–ø–∞—Ç—å –Ω–µ –µ—Å—Ç—å –Ω–µ–±—É...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>64370</td>\n",
       "      <td>–∫–∞–∫–æ–π –º—É–¥–∞–∫ —Å—Ç–∞—Ä–æ–µ –∫–∏–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–Ω–æ–≤—ã–≤–∞–µ—Ç –ø–æ—Å—Ç–æ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>17080</td>\n",
       "      <td>—Å–ø–∏—Ç –æ–Ω –ø–æ–¥ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–æ–º! —è –≤ –≤–æ—Å—Ç–æ—Ä–≥–µ!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>237178</td>\n",
       "      <td>–º–æ–≥—É –ø–Ω—É—Ç—å –ø–æ —è–π—Ü–∞–º –∏ –æ—Ç–ª–µ—Ç–∏—Ç –¥–µ–±–∏–ª —Ç–≤–æ—è –≥–æ–ª–æ–≤–∞</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>26969</td>\n",
       "      <td>—é—Ä–∞ –µ—Ñ—Ä–µ–º–æ–≤ –ø–æ–¥–æ–Ω–æ–∫ –∏ –Ω–µ–≥–æ–¥—è–π –∫ —Ç–æ–º—É –∂–µ –ø–æ–¥–ª–µ–π...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  normal  \\\n",
       "1995   15834  –ª—é–¥–µ–π –∏—Å–∫–∏—Å—Ç–≤–∞ —Ç—è–Ω–µ—Ç ,–æ–Ω –Ω–µ —Å–ø–∞—Ç—å –Ω–µ –µ—Å—Ç—å –Ω–µ–±—É...       1   \n",
       "1996   64370  –∫–∞–∫–æ–π –º—É–¥–∞–∫ —Å—Ç–∞—Ä–æ–µ –∫–∏–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–Ω–æ–≤—ã–≤–∞–µ—Ç –ø–æ—Å—Ç–æ...       0   \n",
       "1997   17080           —Å–ø–∏—Ç –æ–Ω –ø–æ–¥ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–æ–º! —è –≤ –≤–æ—Å—Ç–æ—Ä–≥–µ!       1   \n",
       "1998  237178    –º–æ–≥—É –ø–Ω—É—Ç—å –ø–æ —è–π—Ü–∞–º –∏ –æ—Ç–ª–µ—Ç–∏—Ç –¥–µ–±–∏–ª —Ç–≤–æ—è –≥–æ–ª–æ–≤–∞       0   \n",
       "1999   26969  —é—Ä–∞ –µ—Ñ—Ä–µ–º–æ–≤ –ø–æ–¥–æ–Ω–æ–∫ –∏ –Ω–µ–≥–æ–¥—è–π –∫ —Ç–æ–º—É –∂–µ –ø–æ–¥–ª–µ–π...       0   \n",
       "\n",
       "      insult  obscenity  threat  \n",
       "1995       0          0       0  \n",
       "1996       1          0       0  \n",
       "1997       0          0       0  \n",
       "1998       1          0       1  \n",
       "1999       1          0       0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('short_train.csv', usecols=['id', 'text', 'normal','insult','obscenity','threat'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           69952\n",
       "text         —ç—Ç–æ –æ–±–æ—é–¥–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ‚úå\n",
       "normal                           1\n",
       "insult                           0\n",
       "obscenity                        0\n",
       "threat                           0\n",
       "Name: 94, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—ç—Ç–æ –æ–±–æ—é–¥–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ‚úå'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = df.iloc[94]['text']\n",
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delEmoji(text):\n",
    "    allchars = [str for str in text]\n",
    "    lst = [c for c in allchars if c not in emoji.UNICODE_EMOJI]\n",
    "    lst = ''.join(lst)\n",
    "    if lst !='':\n",
    "        return lst\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         240196\n",
       "text         –æ—Ñ–∏–≥–µ–Ω–Ω–∞—è –±–æ–±–æ–º—á–∫–∞ üò≤\n",
       "normal                          1\n",
       "insult                          0\n",
       "obscenity                       0\n",
       "threat                          0\n",
       "Name: 1130, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–æ—Ñ–∏–≥–µ–Ω–Ω–∞—è –±–æ–±–æ–º—á–∫–∞ '"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = delEmoji(df.iloc[1130]['text'])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S.lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~‚Äî\\\"\\-]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(doc):\n",
    "    doc = re.sub(patterns, ' ', doc)\n",
    "    tokens = []\n",
    "    for token in doc.split():\n",
    "        token = token.strip()\n",
    "        token = delEmoji(token)\n",
    "        if token:\n",
    "            token = morph.normal_forms(token)[0]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        tokens.append(token)\n",
    "    if len(tokens) >= 1:\n",
    "        return tokens\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–æ—Ñ–∏–≥–µ–Ω–Ω—ã–π', '–±–æ–±–æ–º—á–∫–∞']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = lemmatize(df.iloc[1130]['text'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [–¥–≤–æ—Ä–Ω–∏–∫, –Ω–∞–¥–æ, —Ç–æ–∂–µ, —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å]\n",
       "1    [–º–æ–π, —Å—Ç–∞—Ä—à–∏–π, –Ω–µ–¥–µ–ª—è, —à–∏–ø–µ—Ç—å, –Ω–µ, –ø—Ä–∏–Ω–∏–º–∞—Ç—å, ...\n",
       "2                        [–ø–æ–ª–Ω–æ—Å—Ç—å—é, —Å, –≤—ã, —Å–æ–≥–ª–∞—Å–Ω—ã–π]\n",
       "3          [—Ö–æ—Ç—å, –Ω–æ–≥–∞, –≤–≤–µ—Ä—Ö, –Ω–∏—á–µ–≥–æ, –Ω–µ, –∏–∑–º–µ–Ω–∏—Ç—å—Å—è]\n",
       "4                     [–∞, —á—Ç–æ, –∑–Ω–∞—á–∏—Ç, –ª–µ–≤—ã–π, —Ä–µ–±—ë–Ω–æ–∫]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –°–∞–º—ã–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "word_freq = defaultdict(int)\n",
    "for tokens in data[:]:\n",
    "    for token in tokens:\n",
    "        word_freq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6293"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–∏',\n",
       " '–≤',\n",
       " '–Ω–µ',\n",
       " '–∞',\n",
       " '—á—Ç–æ',\n",
       " '–Ω–∞',\n",
       " '—è',\n",
       " '—Å',\n",
       " '–±—ã—Ç—å',\n",
       " '—ç—Ç–æ',\n",
       " '–æ–Ω',\n",
       " '–≤—ã',\n",
       " '–∫–∞–∫',\n",
       " '–≤—Å—ë',\n",
       " '—Ç—ã',\n",
       " '—É',\n",
       " '–æ–Ω–∏',\n",
       " '—Ç–æ',\n",
       " '—Ç–∞–∫–æ–π',\n",
       " '—Ç–∞–∫',\n",
       " '–∑–∞',\n",
       " '–º—ã',\n",
       " '–ø–æ',\n",
       " '–≤–µ—Å—å',\n",
       " '—ç—Ç–æ—Ç',\n",
       " '—á–µ–ª–æ–≤–µ–∫',\n",
       " '–æ',\n",
       " '–∫—Ç–æ',\n",
       " '–∫–∞–∫–æ–π',\n",
       " '–±—ã']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topWords = sorted(word_freq, key=word_freq.get, reverse=True)[:30]\n",
    "topWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "—ç—Ç–∏ —Å–ª–æ–≤–∞ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–∏–ª—å–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏, –∏—Ö –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delTopWords(tokens):\n",
    "    return [token for token in tokens if token not in topWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(delTopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [–¥–≤–æ—Ä–Ω–∏–∫, –Ω–∞–¥–æ, —Ç–æ–∂–µ, —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å]\n",
       "1    [–º–æ–π, —Å—Ç–∞—Ä—à–∏–π, –Ω–µ–¥–µ–ª—è, —à–∏–ø–µ—Ç—å, –ø—Ä–∏–Ω–∏–º–∞—Ç—å, –ø–æ–¥–∫...\n",
       "2                               [–ø–æ–ª–Ω–æ—Å—Ç—å—é, —Å–æ–≥–ª–∞—Å–Ω—ã–π]\n",
       "3              [—Ö–æ—Ç—å, –Ω–æ–≥–∞, –≤–≤–µ—Ä—Ö, –Ω–∏—á–µ–≥–æ, –∏–∑–º–µ–Ω–∏—Ç—å—Å—è]\n",
       "4                             [–∑–Ω–∞—á–∏—Ç, –ª–µ–≤—ã–π, —Ä–µ–±—ë–Ω–æ–∫]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>normal</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41127</td>\n",
       "      <td>[–¥–≤–æ—Ä–Ω–∏–∫, –Ω–∞–¥–æ, —Ç–æ–∂–µ, —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6812</td>\n",
       "      <td>[–º–æ–π, —Å—Ç–∞—Ä—à–∏–π, –Ω–µ–¥–µ–ª—è, —à–∏–ø–µ—Ç—å, –ø—Ä–∏–Ω–∏–º–∞—Ç—å, –ø–æ–¥–∫...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6256</td>\n",
       "      <td>[–ø–æ–ª–Ω–æ—Å—Ç—å—é, —Å–æ–≥–ª–∞—Å–Ω—ã–π]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189636</td>\n",
       "      <td>[—Ö–æ—Ç—å, –Ω–æ–≥–∞, –≤–≤–µ—Ä—Ö, –Ω–∏—á–µ–≥–æ, –∏–∑–º–µ–Ω–∏—Ç—å—Å—è]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99053</td>\n",
       "      <td>[–∑–Ω–∞—á–∏—Ç, –ª–µ–≤—ã–π, —Ä–µ–±—ë–Ω–æ–∫]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  normal  insult  \\\n",
       "0   41127                  [–¥–≤–æ—Ä–Ω–∏–∫, –Ω–∞–¥–æ, —Ç–æ–∂–µ, —É–Ω–∏—á—Ç–æ–∂–∏—Ç—å]       0       0   \n",
       "1    6812  [–º–æ–π, —Å—Ç–∞—Ä—à–∏–π, –Ω–µ–¥–µ–ª—è, —à–∏–ø–µ—Ç—å, –ø—Ä–∏–Ω–∏–º–∞—Ç—å, –ø–æ–¥–∫...       1       0   \n",
       "2    6256                             [–ø–æ–ª–Ω–æ—Å—Ç—å—é, —Å–æ–≥–ª–∞—Å–Ω—ã–π]       1       0   \n",
       "3  189636            [—Ö–æ—Ç—å, –Ω–æ–≥–∞, –≤–≤–µ—Ä—Ö, –Ω–∏—á–µ–≥–æ, –∏–∑–º–µ–Ω–∏—Ç—å—Å—è]       1       0   \n",
       "4   99053                           [–∑–Ω–∞—á–∏—Ç, –ª–µ–≤—ã–π, —Ä–µ–±—ë–Ω–æ–∫]       1       0   \n",
       "\n",
       "   obscenity  threat  \n",
       "0          0       1  \n",
       "1          0       0  \n",
       "2          0       0  \n",
       "3          0       0  \n",
       "4          0       0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>normal</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>15834</td>\n",
       "      <td>[–∏—Å–∫–∏—Å—Ç–≤–æ, —Ç—è–Ω—É—Ç—å, —Å–ø–∞—Ç—å, –µ—Å—Ç—å, –Ω–µ–±—ã—Ç—å, –æ–Ω–±—ã—Ç—å...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>64370</td>\n",
       "      <td>[–º—É–¥–∞–∫, —Å—Ç–∞—Ä–æ–µ, –∫–∏–Ω–æ, –ø–µ—Ä–µ–∏–º–µ–Ω–Ω–æ–≤—ã–≤–∞—Ç—å, –ø–æ—Å—Ç–æ—è...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>17080</td>\n",
       "      <td>[—Å–ø–∞—Ç—å, –ø–æ–¥, –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä, –≤–æ—Å—Ç–æ—Ä–≥]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>237178</td>\n",
       "      <td>[–º–æ—á—å, –ø–Ω—É—Ç—å, —è–π—Ü–æ, –æ—Ç–ª–µ—Ç–µ—Ç—å, –¥–µ–±–∏–ª, —Ç–≤–æ–π, –≥–æ–ª...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>26969</td>\n",
       "      <td>[—é—Ä–∞, –µ—Ñ—Ä–µ–º, –ø–æ–¥–æ–Ω–æ–∫, –Ω–µ–≥–æ–¥—è–π, –∫, —Ç–æ—Ç, –∂–µ, –ø–æ–¥...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  normal  \\\n",
       "1995   15834  [–∏—Å–∫–∏—Å—Ç–≤–æ, —Ç—è–Ω—É—Ç—å, —Å–ø–∞—Ç—å, –µ—Å—Ç—å, –Ω–µ–±—ã—Ç—å, –æ–Ω–±—ã—Ç—å...       1   \n",
       "1996   64370  [–º—É–¥–∞–∫, —Å—Ç–∞—Ä–æ–µ, –∫–∏–Ω–æ, –ø–µ—Ä–µ–∏–º–µ–Ω–Ω–æ–≤—ã–≤–∞—Ç—å, –ø–æ—Å—Ç–æ—è...       0   \n",
       "1997   17080                 [—Å–ø–∞—Ç—å, –ø–æ–¥, –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä, –≤–æ—Å—Ç–æ—Ä–≥]       1   \n",
       "1998  237178  [–º–æ—á—å, –ø–Ω—É—Ç—å, —è–π—Ü–æ, –æ—Ç–ª–µ—Ç–µ—Ç—å, –¥–µ–±–∏–ª, —Ç–≤–æ–π, –≥–æ–ª...       0   \n",
       "1999   26969  [—é—Ä–∞, –µ—Ñ—Ä–µ–º, –ø–æ–¥–æ–Ω–æ–∫, –Ω–µ–≥–æ–¥—è–π, –∫, —Ç–æ—Ç, –∂–µ, –ø–æ–¥...       0   \n",
       "\n",
       "      insult  obscenity  threat  \n",
       "1995       0          0       0  \n",
       "1996       1          0       0  \n",
       "1997       0          0       0  \n",
       "1998       1          0       1  \n",
       "1999       1          0       0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], \n",
    "                                                    df.drop('text', axis=1), \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>normal</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscenity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>180341</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>241550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>45802</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>178744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>76653</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>240196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>80655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>82203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>193207</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>218468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  normal  insult  obscenity  threat\n",
       "81    180341       0       1          0       0\n",
       "915   241550       0       1          0       0\n",
       "1018   45802       0       1          0       0\n",
       "380   178744       0       0          0       1\n",
       "1029   76653       1       0          0       0\n",
       "...      ...     ...     ...        ...     ...\n",
       "1130  240196       1       0          0       0\n",
       "1294   80655       1       0          0       0\n",
       "860    82203       1       0          0       0\n",
       "1459  193207       1       0          0       0\n",
       "1126  218468       1       0          0       0\n",
       "\n",
       "[1340 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81             [—Ä–æ—Ç, —Å–≤–æ–π, –∑–∞–∫—Ä—ã—Ç—å, –ø–æ–¥—Å—Ç–∏–ª–∫–∞, –ø—É—Ç–∏–Ω—Å–∫–∏–π]\n",
       "915     [—Ä–∞–¥–∞, –µ—Å—Ç—å, —Ä–∞–Ω–Ω–∏–π, –¥–æ, –ø–∞–Ω–¥–µ–º–∏—è, –≤—ã–Ω—É–¥–∏—Ç—å, —É...\n",
       "1018    [–∑–∞–µ—Å—Ç–∏, —Å—É–∫–∞, –∫–æ–≥–¥–∞, –∂–µ, –Ω–∞–∂—Ä–∞—Ç—å—Å—è, –ø–∞–¥–ª–∞, –±–ª...\n",
       "380                                    [—Å–¥–æ—Ö–Ω—É—Ç—å, —Å–∫–æ—Ä–µ–µ]\n",
       "1029    [–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, —Å—Ä–æ—á–Ω–æ, –∫–∏–∑–∏–ª, –Ω—É–∂–Ω—ã–π, –Ω–æ, –Ω–µ–º–Ω...\n",
       "                              ...                        \n",
       "1130                             [–æ—Ñ–∏–≥–µ–Ω–Ω—ã–π, –±–æ–±–æ–º—á–∫–∞, üò≤]\n",
       "1294    [–∫–æ—à–º–∞—Ä, —Å—Ä–∞–Ω—å, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–≤—Å–∫–∞–π, –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, —Å–≤...\n",
       "860     [–¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏, –∑–∞—è—Ü, –ø—Ä–æ–ø–∏—Å–∞—Ç—å—Å—è, –¥–∞—á–∞, –≤—ã–≥—Ä—ã–∑...\n",
       "1459                          [—Å–µ—Ä–ø–∞—Ç—ã–π, —Ç–æ—Ä—Ü–æ–≤—ã–π, –∫–ª–∞—Å—Å]\n",
       "1126    [–ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è, –ø–∞—Ä–µ–Ω—å, —Å–∫–∞–∑–∞—Ç—å, –ø–æ–∫–∞, –ø–ª–∞—Ç—å–µ,...\n",
       "Name: text, Length: 1340, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö   \n",
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_vec_train = count_vec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1340x6575 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13895 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_vec_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_vec_test = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "model1.fit(comments_vec_train,y_train['normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(comments_vec_train,y_train['insult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LogisticRegression()\n",
    "model3.fit(comments_vec_train,y_train['obscenity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = LogisticRegression()\n",
    "model4.fit(comments_vec_train,y_train['threat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = model1.predict(comments_vec_test)\n",
    "p2 = model2.predict(comments_vec_test)\n",
    "p3 = model3.predict(comments_vec_test)\n",
    "p4 = model4.predict(comments_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921875"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test['normal'], p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.341399485930736"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1 = np.array([f1_score(y_test['normal'], p1),\n",
    "         f1_score(y_test['insult'], p2),\n",
    "         f1_score(y_test['obscenity'], p3),\n",
    "         f1_score(y_test['threat'], p4),\n",
    "\n",
    "])\n",
    "F1.mean() # F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
